{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuMF-Wei ","provenance":[{"file_id":"1WVkdaBioH5_Bem8Yl-S34mYLviaoDrlG","timestamp":1622412227547}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4Eryx2cRYMB","executionInfo":{"status":"ok","timestamp":1622414354530,"user_tz":420,"elapsed":159,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"437bc28b-0d5c-4eec-fe8a-33b916e90790"},"source":["# Mount your google drive in google colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/CS247/Models')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rI74g72bRfQl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622422282898,"user_tz":420,"elapsed":152,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"ed884629-9777-438d-9e13-093e77fb8fee"},"source":["import numpy as np\n","import pandas as pd\n","from util import *\n","from model import MLPEmbedding\n","from model import GMF\n","from evaluate import *\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":84,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gp2dwImNRgdk","executionInfo":{"status":"ok","timestamp":1622422285405,"user_tz":420,"elapsed":916,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}}},"source":["train_data = pd.read_pickle(\"/content/drive/MyDrive/CS247/Data/train_data.pkl\")\n","val_data = pd.read_pickle(\"/content/drive/MyDrive/CS247/Data/val_data.pkl\")\n","test_data = pd.read_pickle(\"/content/drive/MyDrive/CS247/Data/test_data.pkl\")[['review_profilename','beer_name','review_overall']]\n","test_data = merge_user_id(test_data, on='review_profilename').rename(columns={'id':'user_id'})\n","test_data = merge_beer_id(test_data, on='beer_name').rename(columns={'id':'beer_id'})[['user_id','beer_id','review_overall']]"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"YTpbq64pZUnf","executionInfo":{"status":"ok","timestamp":1622422285751,"user_tz":420,"elapsed":161,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"95fb48d3-ef45-4112-8d82-335cb08a0160"},"source":["# convert review score to boolean - if the item is relevant to the user (rating >= 3.5) then 1, else 0\n","threshold = 4.0\n","train_data['relevant'] = (train_data['review_overall'] >= threshold).astype(int)\n","train_data.head()"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>beer_id</th>\n","      <th>review_overall</th>\n","      <th>relevant</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>383941</th>\n","      <td>415</td>\n","      <td>831</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>483700</th>\n","      <td>2492</td>\n","      <td>3491</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>375376</th>\n","      <td>1233</td>\n","      <td>1178</td>\n","      <td>4.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>705138</th>\n","      <td>1230</td>\n","      <td>902</td>\n","      <td>4.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>435972</th>\n","      <td>2290</td>\n","      <td>7497</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        user_id  beer_id  review_overall  relevant\n","383941      415      831             3.5         0\n","483700     2492     3491             4.0         1\n","375376     1233     1178             4.5         1\n","705138     1230      902             4.5         1\n","435972     2290     7497             3.5         0"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXbPZoGMYXPw","executionInfo":{"status":"ok","timestamp":1622422288522,"user_tz":420,"elapsed":187,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"fbaf6784-1601-43db-9e75-22ac2b2b7fa5"},"source":["### unique users & beers in train_data\n","n_users = len(train_data['user_id'].unique())\n","n_beers = len(train_data['beer_id'].unique())\n","print(\"unique users: \", n_users)\n","print(\"unique beers: \", n_beers)"],"execution_count":87,"outputs":[{"output_type":"stream","text":["unique users:  14811\n","unique beers:  52583\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b06W28jMoO8w"},"source":["# Combined models "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ho4WPoFhxTHG","executionInfo":{"status":"ok","timestamp":1622422289753,"user_tz":420,"elapsed":171,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"b60aeacd-9e23-4cf0-c215-e5ee563f6c6d"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":88,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"46l0zuwon7Tj","executionInfo":{"status":"ok","timestamp":1622422294407,"user_tz":420,"elapsed":174,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}}},"source":["class NeuMF(nn.Module):\n","  def __init__(self, gmf_model, mlp_model, n_input, alpha=0.5, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n","    ## n_input = sum of output shape of the last layer of gmf and mlp model\n","    super().__init__()\n","    self.gmf_model=gmf_model\n","    self.mlp_model=mlp_model\n","    self.device = device\n","    self.net = nn.Linear(30, 1).to(self.device) ## we can add more layers here\n","    \n","  \n","  def forward(self, df):\n","    # df: user_id, beer_id\n","    mlp_out = self.mlp_model.forward(df).to(self.device) # (n,25)\n","    ## TODO: output of the gmf_model\n","    gmf_out = self.gmf_model.forward_no_h(df).to(self.device)\n","    neumf_in = torch.cat((alpha*mlp_out, (1-alpha)*gmf_out), axis=1).to(self.device)\n","    return self.net(neumf_in)\n","\n","  def predict(self, df):\n","    return torch.sigmoid(self.forward(df))\n","\n","  def loss(self, df, loss_fn):\n","    y_pred = self.forward(df).view(-1)\n","    y_train = torch.Tensor(df.relevant.to_numpy()).to(self.device)\n","    \n","    return loss_fn(y_pred, y_train)"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3NjCvxwoIMr","executionInfo":{"status":"ok","timestamp":1622422296206,"user_tz":420,"elapsed":194,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"17dcda58-1c50-4db7-b2c4-9eed4dc84db7"},"source":["# https://discuss.pytorch.org/t/merging-two-models/45637\n","#load the best parameters\n","gmf_model =  GMF(n_users,n_beers)\n","gmf_model.load_state_dict(torch.load(\"/content/drive/MyDrive/CS247/Models/checkpoints/gmf.pth\"))\n","gmf_model.to(device)\n","mlp_model = MLPEmbedding(n_users=n_users, n_beers=n_beers, device=device, hidden_size=150).to(device)\n","mlp_model.load_state_dict(torch.load(\"/content/drive/MyDrive/CS247/Models/checkpoints/mlp_best.pth\")['model_state_dict'])\n"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqI9AmOKW3YC","executionInfo":{"status":"ok","timestamp":1622426934615,"user_tz":420,"elapsed":4250041,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"a424c425-665b-4a65-83cc-24fb1eaf21d0"},"source":["import math\n","\n","# device = gpu\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","## model params\n","mlp_hidden_size = 150\n","gmf_hidden_size = 5\n","epochs = 40\n","batch_size = 500\n","lr = 0.001\n","loss_fn = nn.BCEWithLogitsLoss()\n","label_pred = 'pred_y'\n","alpha=0.6\n","k=5\n","\n","# n_users, n_beers, mlp_hidden_size, gmf_hidden_size, device\n","neu_mf = NeuMF(gmf_model, mlp_model, mlp_hidden_size, device)\n","optimizer = optim.Adam(list(neu_mf.gmf_model.parameters()) + list(neu_mf.mlp_model.parameters()) + list(neu_mf.net.parameters()), lr=1e-4, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [5,10,20], gamma=0.5)\n","\n","l = []\n","val_p = []\n","train_p = []\n","best_p = 0\n","\n","for i in range(epochs):\n","    print(\"epoch: \",i)\n","    s = 0\n","    for bid in range(len(train_data) // batch_size):\n","        if (bid % 300 == 0):\n","          print(\"iteration: \",i, \", batch: \", bid)\n","        data = train_data[bid * batch_size : (bid + 1) * batch_size]\n","        optimizer.zero_grad()\n","        \n","        loss = neu_mf.loss(data, loss_fn)\n","        loss.backward()\n","        optimizer.step()\n","        s += loss\n","        \n","    scheduler.step()\n","    l.append(s.item()/(len(data) // batch_size))  \n","\n","    # evaluate precision at 10 of the model\n","  \n","    neu_mf.eval()\n","    with torch.no_grad():\n","      val = val_data.copy()\n","      val[label_pred] = (neu_mf.predict(val).cpu().detach().numpy() > 0.5).astype(int)\n","      val_prec, _ = precision_recall_at_k(val, label_pred=label_pred, threshold=threshold, k=k)\n","      val_prec = sum(prec for prec in val_prec.values()) / len(val_prec)\n","      train = train_data.copy()\n","      train[label_pred] = (neu_mf.predict(train).cpu().detach().numpy() > 0.5).astype(int)\n","      train_prec, _ = precision_recall_at_k(train, label_pred=label_pred, threshold=threshold, k=k)\n","      train_prec = sum(prec for prec in train_prec.values()) / len(train_prec)\n","\n","      train_p.append(train_prec)\n","      val_p.append(val_prec)\n","    neu_mf.train()\n","    \n","    print(\"Train precision at 5: \", train_prec)\n","    print(\"Validation precision at 5: \", val_prec)\n","    print(\"Current best validation precision at 5: \", best_p)\n","    if val_prec > best_p:\n","      print(\"Validation precision better than best current precision. Saving model to best_state_dict...\")\n","      best_state_dict = {\n","           'model_state_dict': neu_mf.state_dict()\n","           }\n","      best_p = val_prec\n","\n","      \n","    print(\"Average Loss for the current iteration: \", l[i])\n","    print(\"-----------------------------------\")"],"execution_count":101,"outputs":[{"output_type":"stream","text":["epoch:  0\n","iteration:  0 , batch:  0\n","iteration:  0 , batch:  300\n","iteration:  0 , batch:  600\n","iteration:  0 , batch:  900\n","iteration:  0 , batch:  1200\n","iteration:  0 , batch:  1500\n","iteration:  0 , batch:  1800\n","Train precision at 5:  0.772393266266068\n","Validation precision at 5:  0.6926856165462764\n","Current best validation precision at 5:  0\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  933.9694213867188\n","-----------------------------------\n","epoch:  1\n","iteration:  1 , batch:  0\n","iteration:  1 , batch:  300\n","iteration:  1 , batch:  600\n","iteration:  1 , batch:  900\n","iteration:  1 , batch:  1200\n","iteration:  1 , batch:  1500\n","iteration:  1 , batch:  1800\n","Train precision at 5:  0.7772781491234015\n","Validation precision at 5:  0.6904159070960938\n","Current best validation precision at 5:  0.6926856165462764\n","Average Loss for the current iteration:  908.501220703125\n","-----------------------------------\n","epoch:  2\n","iteration:  2 , batch:  0\n","iteration:  2 , batch:  300\n","iteration:  2 , batch:  600\n","iteration:  2 , batch:  900\n","iteration:  2 , batch:  1200\n","iteration:  2 , batch:  1500\n","iteration:  2 , batch:  1800\n","Train precision at 5:  0.7856998177030595\n","Validation precision at 5:  0.6908041320640215\n","Current best validation precision at 5:  0.6926856165462764\n","Average Loss for the current iteration:  887.0835571289062\n","-----------------------------------\n","epoch:  3\n","iteration:  3 , batch:  0\n","iteration:  3 , batch:  300\n","iteration:  3 , batch:  600\n","iteration:  3 , batch:  900\n","iteration:  3 , batch:  1200\n","iteration:  3 , batch:  1500\n","iteration:  3 , batch:  1800\n","Train precision at 5:  0.7983672045551716\n","Validation precision at 5:  0.6924560574348052\n","Current best validation precision at 5:  0.6926856165462764\n","Average Loss for the current iteration:  872.3948974609375\n","-----------------------------------\n","epoch:  4\n","iteration:  4 , batch:  0\n","iteration:  4 , batch:  300\n","iteration:  4 , batch:  600\n","iteration:  4 , batch:  900\n","iteration:  4 , batch:  1200\n","iteration:  4 , batch:  1500\n","iteration:  4 , batch:  1800\n","Train precision at 5:  0.7996635383611265\n","Validation precision at 5:  0.6928431571129726\n","Current best validation precision at 5:  0.6926856165462764\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  863.274169921875\n","-----------------------------------\n","epoch:  5\n","iteration:  5 , batch:  0\n","iteration:  5 , batch:  300\n","iteration:  5 , batch:  600\n","iteration:  5 , batch:  900\n","iteration:  5 , batch:  1200\n","iteration:  5 , batch:  1500\n","iteration:  5 , batch:  1800\n","Train precision at 5:  0.8152049152656775\n","Validation precision at 5:  0.6938109063083893\n","Current best validation precision at 5:  0.6928431571129726\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  848.1900024414062\n","-----------------------------------\n","epoch:  6\n","iteration:  6 , batch:  0\n","iteration:  6 , batch:  300\n","iteration:  6 , batch:  600\n","iteration:  6 , batch:  900\n","iteration:  6 , batch:  1200\n","iteration:  6 , batch:  1500\n","iteration:  6 , batch:  1800\n","Train precision at 5:  0.8252818850854063\n","Validation precision at 5:  0.6929770665946636\n","Current best validation precision at 5:  0.6938109063083893\n","Average Loss for the current iteration:  830.0942993164062\n","-----------------------------------\n","epoch:  7\n","iteration:  7 , batch:  0\n","iteration:  7 , batch:  300\n","iteration:  7 , batch:  600\n","iteration:  7 , batch:  900\n","iteration:  7 , batch:  1200\n","iteration:  7 , batch:  1500\n","iteration:  7 , batch:  1800\n","Train precision at 5:  0.8286183692300739\n","Validation precision at 5:  0.6931616141156502\n","Current best validation precision at 5:  0.6938109063083893\n","Average Loss for the current iteration:  819.2261352539062\n","-----------------------------------\n","epoch:  8\n","iteration:  8 , batch:  0\n","iteration:  8 , batch:  300\n","iteration:  8 , batch:  600\n","iteration:  8 , batch:  900\n","iteration:  8 , batch:  1200\n","iteration:  8 , batch:  1500\n","iteration:  8 , batch:  1800\n","Train precision at 5:  0.8302500393851359\n","Validation precision at 5:  0.6930243287646729\n","Current best validation precision at 5:  0.6938109063083893\n","Average Loss for the current iteration:  812.3472290039062\n","-----------------------------------\n","epoch:  9\n","iteration:  9 , batch:  0\n","iteration:  9 , batch:  300\n","iteration:  9 , batch:  600\n","iteration:  9 , batch:  900\n","iteration:  9 , batch:  1200\n","iteration:  9 , batch:  1500\n","iteration:  9 , batch:  1800\n","Train precision at 5:  0.8377320910134297\n","Validation precision at 5:  0.6922973915783482\n","Current best validation precision at 5:  0.6938109063083893\n","Average Loss for the current iteration:  804.9014282226562\n","-----------------------------------\n","epoch:  10\n","iteration:  10 , batch:  0\n","iteration:  10 , batch:  300\n","iteration:  10 , batch:  600\n","iteration:  10 , batch:  900\n","iteration:  10 , batch:  1200\n","iteration:  10 , batch:  1500\n","iteration:  10 , batch:  1800\n","Train precision at 5:  0.8444804537168249\n","Validation precision at 5:  0.6926090968424526\n","Current best validation precision at 5:  0.6938109063083893\n","Average Loss for the current iteration:  796.6049194335938\n","-----------------------------------\n","epoch:  11\n","iteration:  11 , batch:  0\n","iteration:  11 , batch:  300\n","iteration:  11 , batch:  600\n","iteration:  11 , batch:  900\n","iteration:  11 , batch:  1200\n","iteration:  11 , batch:  1500\n","iteration:  11 , batch:  1800\n","Train precision at 5:  0.85049850336461\n","Validation precision at 5:  0.6950385974388558\n","Current best validation precision at 5:  0.6938109063083893\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  782.0760498046875\n","-----------------------------------\n","epoch:  12\n","iteration:  12 , batch:  0\n","iteration:  12 , batch:  300\n","iteration:  12 , batch:  600\n","iteration:  12 , batch:  900\n","iteration:  12 , batch:  1200\n","iteration:  12 , batch:  1500\n","iteration:  12 , batch:  1800\n","Train precision at 5:  0.8518263452839034\n","Validation precision at 5:  0.6942970314856236\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  774.6492919921875\n","-----------------------------------\n","epoch:  13\n","iteration:  13 , batch:  0\n","iteration:  13 , batch:  300\n","iteration:  13 , batch:  600\n","iteration:  13 , batch:  900\n","iteration:  13 , batch:  1200\n","iteration:  13 , batch:  1500\n","iteration:  13 , batch:  1800\n","Train precision at 5:  0.8554070173069465\n","Validation precision at 5:  0.6935543402426289\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  768.2606811523438\n","-----------------------------------\n","epoch:  14\n","iteration:  14 , batch:  0\n","iteration:  14 , batch:  300\n","iteration:  14 , batch:  600\n","iteration:  14 , batch:  900\n","iteration:  14 , batch:  1200\n","iteration:  14 , batch:  1500\n","iteration:  14 , batch:  1800\n","Train precision at 5:  0.8552584790583488\n","Validation precision at 5:  0.6940190849143809\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  762.2921752929688\n","-----------------------------------\n","epoch:  15\n","iteration:  15 , batch:  0\n","iteration:  15 , batch:  300\n","iteration:  15 , batch:  600\n","iteration:  15 , batch:  900\n","iteration:  15 , batch:  1200\n","iteration:  15 , batch:  1500\n","iteration:  15 , batch:  1800\n","Train precision at 5:  0.859677491954171\n","Validation precision at 5:  0.6917910111853962\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  756.9114990234375\n","-----------------------------------\n","epoch:  16\n","iteration:  16 , batch:  0\n","iteration:  16 , batch:  300\n","iteration:  16 , batch:  600\n","iteration:  16 , batch:  900\n","iteration:  16 , batch:  1200\n","iteration:  16 , batch:  1500\n","iteration:  16 , batch:  1800\n","Train precision at 5:  0.8606519928881601\n","Validation precision at 5:  0.6917336214075277\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  752.5127563476562\n","-----------------------------------\n","epoch:  17\n","iteration:  17 , batch:  0\n","iteration:  17 , batch:  300\n","iteration:  17 , batch:  600\n","iteration:  17 , batch:  900\n","iteration:  17 , batch:  1200\n","iteration:  17 , batch:  1500\n","iteration:  17 , batch:  1800\n","Train precision at 5:  0.862884567776192\n","Validation precision at 5:  0.6939054306484083\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  750.102294921875\n","-----------------------------------\n","epoch:  18\n","iteration:  18 , batch:  0\n","iteration:  18 , batch:  300\n","iteration:  18 , batch:  600\n","iteration:  18 , batch:  900\n","iteration:  18 , batch:  1200\n","iteration:  18 , batch:  1500\n","iteration:  18 , batch:  1800\n","Train precision at 5:  0.8634944748272583\n","Validation precision at 5:  0.6929635631175188\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  744.7803955078125\n","-----------------------------------\n","epoch:  19\n","iteration:  19 , batch:  0\n","iteration:  19 , batch:  300\n","iteration:  19 , batch:  600\n","iteration:  19 , batch:  900\n","iteration:  19 , batch:  1200\n","iteration:  19 , batch:  1500\n","iteration:  19 , batch:  1800\n","Train precision at 5:  0.8587356244232793\n","Validation precision at 5:  0.694412936331121\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  742.0302124023438\n","-----------------------------------\n","epoch:  20\n","iteration:  20 , batch:  0\n","iteration:  20 , batch:  300\n","iteration:  20 , batch:  600\n","iteration:  20 , batch:  900\n","iteration:  20 , batch:  1200\n","iteration:  20 , batch:  1500\n","iteration:  20 , batch:  1800\n","Train precision at 5:  0.8696520604055459\n","Validation precision at 5:  0.6931514865077902\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  736.7620849609375\n","-----------------------------------\n","epoch:  21\n","iteration:  21 , batch:  0\n","iteration:  21 , batch:  300\n","iteration:  21 , batch:  600\n","iteration:  21 , batch:  900\n","iteration:  21 , batch:  1200\n","iteration:  21 , batch:  1500\n","iteration:  21 , batch:  1800\n","Train precision at 5:  0.8707109580716946\n","Validation precision at 5:  0.6938109063083897\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  728.1817626953125\n","-----------------------------------\n","epoch:  22\n","iteration:  22 , batch:  0\n","iteration:  22 , batch:  300\n","iteration:  22 , batch:  600\n","iteration:  22 , batch:  900\n","iteration:  22 , batch:  1200\n","iteration:  22 , batch:  1500\n","iteration:  22 , batch:  1800\n","Train precision at 5:  0.8728265028244679\n","Validation precision at 5:  0.6938682960862574\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  720.881103515625\n","-----------------------------------\n","epoch:  23\n","iteration:  23 , batch:  0\n","iteration:  23 , batch:  300\n","iteration:  23 , batch:  600\n","iteration:  23 , batch:  900\n","iteration:  23 , batch:  1200\n","iteration:  23 , batch:  1500\n","iteration:  23 , batch:  1800\n","Train precision at 5:  0.8732428600364505\n","Validation precision at 5:  0.6941597461346452\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  717.6979370117188\n","-----------------------------------\n","epoch:  24\n","iteration:  24 , batch:  0\n","iteration:  24 , batch:  300\n","iteration:  24 , batch:  600\n","iteration:  24 , batch:  900\n","iteration:  24 , batch:  1200\n","iteration:  24 , batch:  1500\n","iteration:  24 , batch:  1800\n","Train precision at 5:  0.8793104224337678\n","Validation precision at 5:  0.6937186325478971\n","Current best validation precision at 5:  0.6950385974388558\n","Average Loss for the current iteration:  714.3613891601562\n","-----------------------------------\n","epoch:  25\n","iteration:  25 , batch:  0\n","iteration:  25 , batch:  300\n","iteration:  25 , batch:  600\n","iteration:  25 , batch:  900\n","iteration:  25 , batch:  1200\n","iteration:  25 , batch:  1500\n","iteration:  25 , batch:  1800\n","Train precision at 5:  0.8772837755721999\n","Validation precision at 5:  0.6950757320010055\n","Current best validation precision at 5:  0.6950385974388558\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  712.0143432617188\n","-----------------------------------\n","epoch:  26\n","iteration:  26 , batch:  0\n","iteration:  26 , batch:  300\n","iteration:  26 , batch:  600\n","iteration:  26 , batch:  900\n","iteration:  26 , batch:  1200\n","iteration:  26 , batch:  1500\n","iteration:  26 , batch:  1800\n","Train precision at 5:  0.8799608399162687\n","Validation precision at 5:  0.6945704768978167\n","Current best validation precision at 5:  0.6950757320010055\n","Average Loss for the current iteration:  709.0285034179688\n","-----------------------------------\n","epoch:  27\n","iteration:  27 , batch:  0\n","iteration:  27 , batch:  300\n","iteration:  27 , batch:  600\n","iteration:  27 , batch:  900\n","iteration:  27 , batch:  1200\n","iteration:  27 , batch:  1500\n","iteration:  27 , batch:  1800\n","Train precision at 5:  0.8767965251052079\n","Validation precision at 5:  0.6937107555195619\n","Current best validation precision at 5:  0.6950757320010055\n","Average Loss for the current iteration:  706.1581420898438\n","-----------------------------------\n","epoch:  28\n","iteration:  28 , batch:  0\n","iteration:  28 , batch:  300\n","iteration:  28 , batch:  600\n","iteration:  28 , batch:  900\n","iteration:  28 , batch:  1200\n","iteration:  28 , batch:  1500\n","iteration:  28 , batch:  1800\n","Train precision at 5:  0.8762822676839211\n","Validation precision at 5:  0.694123736862258\n","Current best validation precision at 5:  0.6950757320010055\n","Average Loss for the current iteration:  703.8067626953125\n","-----------------------------------\n","epoch:  29\n","iteration:  29 , batch:  0\n","iteration:  29 , batch:  300\n","iteration:  29 , batch:  600\n","iteration:  29 , batch:  900\n","iteration:  29 , batch:  1200\n","iteration:  29 , batch:  1500\n","iteration:  29 , batch:  1800\n","Train precision at 5:  0.8819413498975902\n","Validation precision at 5:  0.6946807552945038\n","Current best validation precision at 5:  0.6950757320010055\n","Average Loss for the current iteration:  703.1119384765625\n","-----------------------------------\n","epoch:  30\n","iteration:  30 , batch:  0\n","iteration:  30 , batch:  300\n","iteration:  30 , batch:  600\n","iteration:  30 , batch:  900\n","iteration:  30 , batch:  1200\n","iteration:  30 , batch:  1500\n","iteration:  30 , batch:  1800\n","Train precision at 5:  0.8797504107307555\n","Validation precision at 5:  0.694585105664724\n","Current best validation precision at 5:  0.6950757320010055\n","Average Loss for the current iteration:  699.6730346679688\n","-----------------------------------\n","epoch:  31\n","iteration:  31 , batch:  0\n","iteration:  31 , batch:  300\n","iteration:  31 , batch:  600\n","iteration:  31 , batch:  900\n","iteration:  31 , batch:  1200\n","iteration:  31 , batch:  1500\n","iteration:  31 , batch:  1800\n","Train precision at 5:  0.8793115477235302\n","Validation precision at 5:  0.6957430288299395\n","Current best validation precision at 5:  0.6950757320010055\n","Validation precision better than best current precision. Saving model to best_state_dict...\n","Average Loss for the current iteration:  698.17919921875\n","-----------------------------------\n","epoch:  32\n","iteration:  32 , batch:  0\n","iteration:  32 , batch:  300\n","iteration:  32 , batch:  600\n","iteration:  32 , batch:  900\n","iteration:  32 , batch:  1200\n","iteration:  32 , batch:  1500\n","iteration:  32 , batch:  1800\n","Train precision at 5:  0.8846217901109452\n","Validation precision at 5:  0.6934249319199852\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  696.5450439453125\n","-----------------------------------\n","epoch:  33\n","iteration:  33 , batch:  0\n","iteration:  33 , batch:  300\n","iteration:  33 , batch:  600\n","iteration:  33 , batch:  900\n","iteration:  33 , batch:  1200\n","iteration:  33 , batch:  1500\n","iteration:  33 , batch:  1800\n","Train precision at 5:  0.8856818130668567\n","Validation precision at 5:  0.6921364751423644\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  693.8887329101562\n","-----------------------------------\n","epoch:  34\n","iteration:  34 , batch:  0\n","iteration:  34 , batch:  300\n","iteration:  34 , batch:  600\n","iteration:  34 , batch:  900\n","iteration:  34 , batch:  1200\n","iteration:  34 , batch:  1500\n","iteration:  34 , batch:  1800\n","Train precision at 5:  0.8858596088492711\n","Validation precision at 5:  0.6933585398240195\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  692.5209350585938\n","-----------------------------------\n","epoch:  35\n","iteration:  35 , batch:  0\n","iteration:  35 , batch:  300\n","iteration:  35 , batch:  600\n","iteration:  35 , batch:  900\n","iteration:  35 , batch:  1200\n","iteration:  35 , batch:  1500\n","iteration:  35 , batch:  1800\n","Train precision at 5:  0.884674678729765\n","Validation precision at 5:  0.6934339342380808\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  691.1205444335938\n","-----------------------------------\n","epoch:  36\n","iteration:  36 , batch:  0\n","iteration:  36 , batch:  300\n","iteration:  36 , batch:  600\n","iteration:  36 , batch:  900\n","iteration:  36 , batch:  1200\n","iteration:  36 , batch:  1500\n","iteration:  36 , batch:  1800\n","Train precision at 5:  0.8864616388720005\n","Validation precision at 5:  0.6944534467625566\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  689.26904296875\n","-----------------------------------\n","epoch:  37\n","iteration:  37 , batch:  0\n","iteration:  37 , batch:  300\n","iteration:  37 , batch:  600\n","iteration:  37 , batch:  900\n","iteration:  37 , batch:  1200\n","iteration:  37 , batch:  1500\n","iteration:  37 , batch:  1800\n","Train precision at 5:  0.8850876600724614\n","Validation precision at 5:  0.6921871131816589\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  687.7237548828125\n","-----------------------------------\n","epoch:  38\n","iteration:  38 , batch:  0\n","iteration:  38 , batch:  300\n","iteration:  38 , batch:  600\n","iteration:  38 , batch:  900\n","iteration:  38 , batch:  1200\n","iteration:  38 , batch:  1500\n","iteration:  38 , batch:  1800\n","Train precision at 5:  0.8851540521684239\n","Validation precision at 5:  0.694836045281675\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  686.6907348632812\n","-----------------------------------\n","epoch:  39\n","iteration:  39 , batch:  0\n","iteration:  39 , batch:  300\n","iteration:  39 , batch:  600\n","iteration:  39 , batch:  900\n","iteration:  39 , batch:  1200\n","iteration:  39 , batch:  1500\n","iteration:  39 , batch:  1800\n","Train precision at 5:  0.8852823352013056\n","Validation precision at 5:  0.6932257556320901\n","Current best validation precision at 5:  0.6957430288299395\n","Average Loss for the current iteration:  685.867431640625\n","-----------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"yYr-Y7x-ZXAF","executionInfo":{"status":"ok","timestamp":1622426982358,"user_tz":420,"elapsed":429,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"c9e84472-3912-41d2-9ade-752813fa4648"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(val_p, color='b', label='Validation')\n","plt.plot(train_p, color='r', label='Training')\n","plt.vlines(np.argmax(val_p),0.67,1.0, linestyles='dashed', label='Best model')\n","plt.ylabel('Precision@5')\n","plt.xlabel('Epochs')\n","plt.legend()\n","plt.show()"],"execution_count":102,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"0tMoJ8NoztIA","executionInfo":{"status":"ok","timestamp":1622427512570,"user_tz":420,"elapsed":338,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}}},"source":["## n_users=14811\n","## n_beers=52583\n","## device:gpu\n","hidden_size=150\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","best_model = NeuMF(gmf_model, mlp_model, hidden_size, device)\n","torch.save(best_state_dict, \"/content/drive/MyDrive/CS247/Models/checkpoints/neu_mf.pth\")\n","# best_model.load_state_dict(best_state_dict['model_state_dict'])"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"aW6pU4oXz2_N","executionInfo":{"status":"ok","timestamp":1622427515432,"user_tz":420,"elapsed":443,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"ab5415a1-0471-4a62-fb51-6549ea782e85"},"source":["#label_pred = 'pred_y'\n","best_model.to(device)\n","best_model.eval()\n","test_data[label_pred] = (best_model.predict(test_data)>0.5).cpu().detach().numpy().astype(int)\n","test_data"],"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>beer_id</th>\n","      <th>review_overall</th>\n","      <th>pred_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5892</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5892</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>5892</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>5892</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17</td>\n","      <td>5892</td>\n","      <td>5.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>300822</th>\n","      <td>14731</td>\n","      <td>14334</td>\n","      <td>2.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>300823</th>\n","      <td>14776</td>\n","      <td>42943</td>\n","      <td>4.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>300824</th>\n","      <td>14780</td>\n","      <td>22042</td>\n","      <td>4.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>300825</th>\n","      <td>14785</td>\n","      <td>36467</td>\n","      <td>3.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>300826</th>\n","      <td>14790</td>\n","      <td>46338</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300827 rows × 4 columns</p>\n","</div>"],"text/plain":["        user_id  beer_id  review_overall  pred_y\n","0             0     5892             4.0       1\n","1             2     5892             4.0       1\n","2             9     5892             4.0       1\n","3            12     5892             4.0       1\n","4            17     5892             5.0       1\n","...         ...      ...             ...     ...\n","300822    14731    14334             2.5       0\n","300823    14776    42943             4.5       0\n","300824    14780    22042             4.5       1\n","300825    14785    36467             3.5       1\n","300826    14790    46338             2.0       0\n","\n","[300827 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"id":"4tdPoyk4O0RJ","outputId":"339ed978-e304-4e4f-e8f8-8455bbe449e7"},"source":["#threshold=4\n","#k=5\n","test_prec, test_recall = precision_recall_at_k(test_data, label_pred=label_pred, threshold=threshold, k=k)\n","# Precision and recall can then be averaged over all users\n","print(\"precision at 5 for test set: \", sum(prec for prec in test_prec.values()) / len(test_prec))\n","print(\"recall at 5 for test set:\", sum(rec for rec in test_recall.values()) / len(test_prec))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["precision at 5 for test set:  0.6406764394604831\n","recall at 5 for test set: 0.5465328089842406\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VR3zFvLO0RK","outputId":"da3d1787-2f2f-449e-a827-74a46399eb18"},"source":["best_model.eval()\n","val_data[label_pred] = (best_model.predict(val_data)>0.5).cpu().detach().numpy().astype(int)\n","val_prec, val_recall = precision_recall_at_k(val_data, label_pred=label_pred, threshold=threshold, k=k)\n","# Precision and recall can then be averaged over all users\n","print(\"precision at 5 for validation set: \", sum(prec for prec in val_prec.values()) / len(val_prec))\n","print(\"recall at 5 for validation set:\", sum(rec for rec in val_recall.values()) / len(val_prec))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["precision at 5 for validation set:  0.6554148943353072\n","recall at 5 for validation set: 0.5729507226299717\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ty_9lJoyz856","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1622427627747,"user_tz":420,"elapsed":153,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"f2803550-4148-4f0f-81c7-63555e5ebd5a"},"source":["test_data[test_data['user_id']==0]"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>beer_id</th>\n","      <th>review_overall</th>\n","      <th>pred_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5892</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>0</td>\n","      <td>9202</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>0</td>\n","      <td>18492</td>\n","      <td>3.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>0</td>\n","      <td>5624</td>\n","      <td>3.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>0</td>\n","      <td>4872</td>\n","      <td>4.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>44485</th>\n","      <td>0</td>\n","      <td>18487</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44487</th>\n","      <td>0</td>\n","      <td>18466</td>\n","      <td>3.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44490</th>\n","      <td>0</td>\n","      <td>5748</td>\n","      <td>4.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44543</th>\n","      <td>0</td>\n","      <td>12886</td>\n","      <td>3.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44544</th>\n","      <td>0</td>\n","      <td>7941</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1096 rows × 4 columns</p>\n","</div>"],"text/plain":["       user_id  beer_id  review_overall  pred_y\n","0            0     5892             4.0       1\n","96           0     9202             4.0       1\n","156          0    18492             3.5       1\n","161          0     5624             3.5       1\n","220          0     4872             4.5       1\n","...        ...      ...             ...     ...\n","44485        0    18487             4.0       1\n","44487        0    18466             3.5       1\n","44490        0     5748             4.5       1\n","44543        0    12886             3.5       1\n","44544        0     7941             4.0       1\n","\n","[1096 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"id":"N293ZTvzz8-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622427632630,"user_tz":420,"elapsed":183,"user":{"displayName":"WEI ZHOU","photoUrl":"","userId":"10658339737959932030"}},"outputId":"20506236-a265-4516-bc30-09589e15560c"},"source":["precisions, recalls = precision_recall_at_k(test_data[test_data['user_id']==0], label_pred=label_pred, threshold=threshold, k=k)\n","print(\"precision at 5 for user 0: \", sum(prec for prec in precisions.values()) / len(precisions))\n","print(\"recall at 5 for user 0:\", sum(rec for rec in recalls.values()) / len(recalls))"],"execution_count":115,"outputs":[{"output_type":"stream","text":["precision at 5 for user 0:  0.4\n","recall at 5 for user 0: 0.0034602076124567475\n"],"name":"stdout"}]}]}