{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train Val Splitting","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqA0YGGKLsn5YgJbwNSIzI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NellfNh5QOvh","executionInfo":{"status":"ok","timestamp":1622087561687,"user_tz":240,"elapsed":128,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}},"outputId":"9894b36a-3483-431d-9b55-2275d37f8636"},"source":["# Mount your google drive in google colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/CS247/Models')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pc2lfGPcQTO4","executionInfo":{"status":"ok","timestamp":1622087561816,"user_tz":240,"elapsed":1,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}},"outputId":"284e0bf3-2327-4efc-b4b0-65918df4385d"},"source":["import numpy as np\n","import pandas as pd\n","from util import *\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":7,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDjlx5vpQV4D","executionInfo":{"status":"ok","timestamp":1622087569774,"user_tz":240,"elapsed":1481,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}}},"source":["data = pd.read_pickle(\"/content/drive/MyDrive/CS247/Data/full_training_data.pkl\")[['review_profilename','beer_name','review_overall']]\n","data = merge_user_id(data, on='review_profilename').rename(columns={'id':'user_id'})\n","data = merge_beer_id(data, on='beer_name').rename(columns={'id':'beer_id'})[['user_id','beer_id','review_overall']]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLvHozw1Qf7s","executionInfo":{"status":"ok","timestamp":1622087570262,"user_tz":240,"elapsed":124,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}}},"source":["### from https://stackoverflow.com/questions/35393775/how-can-i-ensure-that-the-users-and-items-appear-in-both-train-and-test-data-set\n","def train_test_split(ratings, train_rate=3/4):\n","        \"\"\"\n","        Split ratings into Training set and Test set\n","\n","        \"\"\"\n","\n","        ### shuffle the dataframe and put the beers with only one rating on the top of the dataframe\n","        ### so that they will be placed in the training set\n","        ct = ratings.groupby('beer_id').count()['user_id']\n","        one_review_beers = ct[ct == 1].index.to_numpy()\n","        data = ratings.sample(frac=1)\n","        data['new'] = range(1,len(data)+1)\n","        data.loc[data['beer_id'].isin(one_review_beers), 'new'] = 0\n","        data = data.sort_values(by='new', ascending=True).reset_index().drop(['new','index'], axis=1)\n","\n","        grps = data.groupby('user_id').groups\n","        test_df_index = list()\n","        train_df_index = list()\n","\n","        test_iid = list()\n","        train_iid = list()\n","\n","        c = 0\n","        for key in grps:\n","            count = 0\n","            local_index = list()\n","            grp = np.array(list(grps[key]))\n","\n","            n_train = int(len(grp) * train_rate)\n","            for i, index in enumerate(grp):\n","                if count >= n_train:\n","                    break\n","                if data.iloc[index]['beer_id'] in train_iid:\n","                    continue\n","                train_iid.append(data.iloc[index]['beer_id'])\n","                train_df_index.append(index)\n","                local_index.append(i)\n","                count += 1\n","\n","            grp = np.delete(grp, local_index)\n","\n","            if count < n_train:\n","                local_index = list()\n","                for i, index in enumerate(grp):\n","                    if count >= n_train:\n","                        break\n","                    train_iid.append(data.iloc[index]['beer_id'])\n","                    train_df_index.append(index)\n","                    local_index.append(i)\n","                    count += 1\n","\n","                grp = np.delete(grp, local_index)\n","\n","            test_df_index.append(grp)\n","            c = c+1\n","            if c % 100 == 0:\n","              print(\"finished splitting for {} users\".format(c))\n","        test_df_index = np.hstack(np.array(test_df_index))\n","        train_df_index = np.hstack(np.array(train_df_index))\n","\n","        np.random.shuffle(test_df_index)\n","        np.random.shuffle(train_df_index)\n","\n","        return data.iloc[train_df_index], data.iloc[test_df_index]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5vhGAASQh8w","executionInfo":{"status":"ok","timestamp":1622088266625,"user_tz":240,"elapsed":693467,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}},"outputId":"c137088c-35ae-4014-c173-5200b745b4b1"},"source":["train_data, val_data = train_test_split(data, 3/4)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["finished splitting for 100 users\n","finished splitting for 200 users\n","finished splitting for 300 users\n","finished splitting for 400 users\n","finished splitting for 500 users\n","finished splitting for 600 users\n","finished splitting for 700 users\n","finished splitting for 800 users\n","finished splitting for 900 users\n","finished splitting for 1000 users\n","finished splitting for 1100 users\n","finished splitting for 1200 users\n","finished splitting for 1300 users\n","finished splitting for 1400 users\n","finished splitting for 1500 users\n","finished splitting for 1600 users\n","finished splitting for 1700 users\n","finished splitting for 1800 users\n","finished splitting for 1900 users\n","finished splitting for 2000 users\n","finished splitting for 2100 users\n","finished splitting for 2200 users\n","finished splitting for 2300 users\n","finished splitting for 2400 users\n","finished splitting for 2500 users\n","finished splitting for 2600 users\n","finished splitting for 2700 users\n","finished splitting for 2800 users\n","finished splitting for 2900 users\n","finished splitting for 3000 users\n","finished splitting for 3100 users\n","finished splitting for 3200 users\n","finished splitting for 3300 users\n","finished splitting for 3400 users\n","finished splitting for 3500 users\n","finished splitting for 3600 users\n","finished splitting for 3700 users\n","finished splitting for 3800 users\n","finished splitting for 3900 users\n","finished splitting for 4000 users\n","finished splitting for 4100 users\n","finished splitting for 4200 users\n","finished splitting for 4300 users\n","finished splitting for 4400 users\n","finished splitting for 4500 users\n","finished splitting for 4600 users\n","finished splitting for 4700 users\n","finished splitting for 4800 users\n","finished splitting for 4900 users\n","finished splitting for 5000 users\n","finished splitting for 5100 users\n","finished splitting for 5200 users\n","finished splitting for 5300 users\n","finished splitting for 5400 users\n","finished splitting for 5500 users\n","finished splitting for 5600 users\n","finished splitting for 5700 users\n","finished splitting for 5800 users\n","finished splitting for 5900 users\n","finished splitting for 6000 users\n","finished splitting for 6100 users\n","finished splitting for 6200 users\n","finished splitting for 6300 users\n","finished splitting for 6400 users\n","finished splitting for 6500 users\n","finished splitting for 6600 users\n","finished splitting for 6700 users\n","finished splitting for 6800 users\n","finished splitting for 6900 users\n","finished splitting for 7000 users\n","finished splitting for 7100 users\n","finished splitting for 7200 users\n","finished splitting for 7300 users\n","finished splitting for 7400 users\n","finished splitting for 7500 users\n","finished splitting for 7600 users\n","finished splitting for 7700 users\n","finished splitting for 7800 users\n","finished splitting for 7900 users\n","finished splitting for 8000 users\n","finished splitting for 8100 users\n","finished splitting for 8200 users\n","finished splitting for 8300 users\n","finished splitting for 8400 users\n","finished splitting for 8500 users\n","finished splitting for 8600 users\n","finished splitting for 8700 users\n","finished splitting for 8800 users\n","finished splitting for 8900 users\n","finished splitting for 9000 users\n","finished splitting for 9100 users\n","finished splitting for 9200 users\n","finished splitting for 9300 users\n","finished splitting for 9400 users\n","finished splitting for 9500 users\n","finished splitting for 9600 users\n","finished splitting for 9700 users\n","finished splitting for 9800 users\n","finished splitting for 9900 users\n","finished splitting for 10000 users\n","finished splitting for 10100 users\n","finished splitting for 10200 users\n","finished splitting for 10300 users\n","finished splitting for 10400 users\n","finished splitting for 10500 users\n","finished splitting for 10600 users\n","finished splitting for 10700 users\n","finished splitting for 10800 users\n","finished splitting for 10900 users\n","finished splitting for 11000 users\n","finished splitting for 11100 users\n","finished splitting for 11200 users\n","finished splitting for 11300 users\n","finished splitting for 11400 users\n","finished splitting for 11500 users\n","finished splitting for 11600 users\n","finished splitting for 11700 users\n","finished splitting for 11800 users\n","finished splitting for 11900 users\n","finished splitting for 12000 users\n","finished splitting for 12100 users\n","finished splitting for 12200 users\n","finished splitting for 12300 users\n","finished splitting for 12400 users\n","finished splitting for 12500 users\n","finished splitting for 12600 users\n","finished splitting for 12700 users\n","finished splitting for 12800 users\n","finished splitting for 12900 users\n","finished splitting for 13000 users\n","finished splitting for 13100 users\n","finished splitting for 13200 users\n","finished splitting for 13300 users\n","finished splitting for 13400 users\n","finished splitting for 13500 users\n","finished splitting for 13600 users\n","finished splitting for 13700 users\n","finished splitting for 13800 users\n","finished splitting for 13900 users\n","finished splitting for 14000 users\n","finished splitting for 14100 users\n","finished splitting for 14200 users\n","finished splitting for 14300 users\n","finished splitting for 14400 users\n","finished splitting for 14500 users\n","finished splitting for 14600 users\n","finished splitting for 14700 users\n","finished splitting for 14800 users\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FtwW9pv8QueL","executionInfo":{"status":"aborted","timestamp":1622085857055,"user_tz":240,"elapsed":161,"user":{"displayName":"TONG WU","photoUrl":"","userId":"01876243748839276301"}}},"source":["train_data.to_pickle('/content/drive/MyDrive/CS247/Data/train_data.pkl')\n","val_data.to_pickle('/content/drive/MyDrive/CS247/Data/val_data.pkl')"],"execution_count":null,"outputs":[]}]}